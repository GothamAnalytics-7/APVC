{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b317c03-b009-41a7-8631-0435956c9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c387a92-6a2a-436b-b115-f5f7304e1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_storage_path = \"optuna_journal_storage.log\"\n",
    "lock_obj = optuna.storages.journal.JournalFileOpenLock(optuna_storage_path)\n",
    "storage = optuna.storages.JournalStorage(\n",
    "    optuna.storages.journal.JournalFileBackend(optuna_storage_path, lock_obj=lock_obj)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91afca99-721b-4b8a-85b5-2c1900c6cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),  # Espelhamento horizontal\n",
    "    layers.RandomRotation(0.1),  # Rotação até ±10%\n",
    "    layers.RandomZoom(0.1),  # Zoom in/out até ±10%\n",
    "    layers.RandomContrast(0.1),  # Ajuste de contraste\n",
    "    layers.RandomBrightness(0.1),  # Ajuste de brilho\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e32315f-f3ff-4100-873d-3c341c0319f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial: optuna.Trial) -> tf.keras.Sequential:\n",
    "    params = {\n",
    "        \"use_data_augmentation\"  : trial.suggest_categorical(\"use_data_augmentation\", [False, True]),    # Data Augmentation control\n",
    "        \"use_dropout\"            : trial.suggest_categorical(\"use_dropout\", [False, True]),              # Dropout control\n",
    "        \"use_batch_normalization\": trial.suggest_categorical(\"use_batch_normalization\", [False, True]),  # Batch Normalization control\n",
    "        \"n_layers_CNN\"           : trial.suggest_int(\"n_layers_CNN\", 1, 6),                              # Number of CNN layers control \n",
    "        \"pool_every_n_layers\"    : trial.suggest_int(\"pool_every_n_layers\", 1, 3),                       # When to pool control\n",
    "        \"n_layers_hidden\"        : trial.suggest_int(\"n_layers_hidden\", 1, 2)                            # Number of dense layers control\n",
    "    }\n",
    "    model = tf.keras.Sequential(\n",
    "        tf.keras.layers.Input(shape=(img_height, img_width, 3)),\n",
    "    )\n",
    "    if params[\"use_data_augmentation\"]:  # If True, add data augmentation layer\n",
    "        model.add(data_augmentation)\n",
    "    for i_layer in range(params[\"n_layers_CNN\"]):  # For suggested number of CNN layers\n",
    "        params[f\"CNN_layer{i_layer}\"] = {\n",
    "            \"n_filters\"  : trial.suggest_int(f\"CNN_layer{i_layer}_n_filters\", 4, 1024, log=True),       # N filters for current CNN layer\n",
    "            \"kernel_size\": trial.suggest_int(f\"CNN_layer{i_layer}_kernel_size\", 2, 6),                  # Kernel size for current layer\n",
    "            \"activation\" : trial.suggest_categorical(f\"CNN_layer{i_layer}_activation\", [None, \"relu\"])  # Activation for current layer\n",
    "        }\n",
    "        \n",
    "        model.add(\n",
    "            layers.Conv2D(\n",
    "                filters=params[f\"CNN_layer{i_layer}\"][\"n_filters\"], \n",
    "                kernel_size=params[f\"CNN_layer{i_layer}\"][\"kernel_size\"], \n",
    "                padding=\"same\",\n",
    "                activation=None\n",
    "            )\n",
    "        )\n",
    "        if params[\"use_batch_normalization\"]:  # If True, add Batch normalization\n",
    "            model.add(layers.BatchNormalization())\n",
    "        if params[f\"CNN_layer{i_layer}\"][\"activation\"]:  # If not None, add selected activation layer\n",
    "            model.add(layers.Activation(params[f\"CNN_layer{i_layer}\"][\"activation\"]))\n",
    "        if i_layer % params[\"pool_every_n_layers\"] == 0:  # If current layer number is divisible by pooling control, add pooling layer\n",
    "            params[f\"CNN_layer{i_layer}\"][\"pool_size\"] = trial.suggest_int(f\"CNN_layer{i_layer}_pool_size\", 1, 3)  # Pool size for current layer\n",
    "            model.add(layers.MaxPooling2D(params[f\"CNN_layer{i_layer}\"][\"pool_size\"]))\n",
    "    model.add(layers.Flatten())\n",
    "    for i_layer in range(params[\"n_layers_hidden\"]):  # For suggested number of hidden layers\n",
    "        params[f\"hidden_layer{i_layer}\"] = {\n",
    "            \"n_neurons\": trial.suggest_int(2, 1024, log=True)  # N neurons for current hidden layer\n",
    "        }\n",
    "        model.add(layers.Dense(params[f\"hidden_layer{i_layer}\"][\"n_neurons\"], activation=None))\n",
    "        if params[\"use_batch_normalization\"]:  # If True, add Batch normalization\n",
    "            model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Activation(\"relu\"))\n",
    "    if params[\"use_dropout\"]:  # If True, add Dropout\n",
    "        params[\"dropout_rate\"] = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)  # Dropout rate for current model\n",
    "        model.add(layers.Dropout(params[\"dropout_rate\"]))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))  # Output layer\n",
    "    trial.set_user_attr(\"model_params\", params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83d03b20-3e56-4510-abfb-ceebf855fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(trial: optuna.Trial) -> tf.optimizers.Adam:\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-1, log=True)  # Learning Rate control\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    trial.set_user_attr(\"learning_rate\", learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6035a7b0-3d06-454b-ad2a-6d9f60d374b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    model = create_model(trial)  # Run model construction optimization\n",
    "    optimizer = create_optimizer(trial)  # Run optimizer construction optimization\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "    )\n",
    "    history = model.fit( \n",
    "        train, \n",
    "        epochs=50, \n",
    "        validation_data=validation,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    score = min(history.history[\"val_loss\"])  # Get best validation loss score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53d36112-7e61-446b-b8c0-7f31d66cb3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 16:12:12,788] Using an existing study with name 'cats_and_dogs_cnn_model' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "# Create optuna study with defined function and storage\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    storage=storage,\n",
    "    study_name=f\"cats_and_dogs_cnn_model\",\n",
    "    load_if_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3991c32e-8eef-486d-8c7d-be4b59780c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-03-28 16:20:01,480] Trial 0 failed with parameters: {'use_data_augmentation': True, 'use_dropout': False, 'use_batch_normalization': False, 'n_layers_CNN': 4, 'pool_every_n_layers': 1, 'n_layers_hidden': 1} because of the following error: NameError(\"name 'img_height' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avey\\miniforge3\\envs\\apvc\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Avey\\AppData\\Local\\Temp\\ipykernel_20128\\1207857609.py\", line 2, in objective\n",
      "    model = create_model(trial)  # Run model construction optimization\n",
      "  File \"C:\\Users\\Avey\\AppData\\Local\\Temp\\ipykernel_20128\\2304656070.py\", line 11, in create_model\n",
      "    tf.keras.layers.Input(shape=(img_height, img_width, 3)),\n",
      "NameError: name 'img_height' is not defined\n",
      "[W 2025-03-28 16:20:01,484] Trial 0 failed with value None.\n",
      "[W 2025-03-28 16:20:01,491] Trial 1 failed with parameters: {'use_data_augmentation': True, 'use_dropout': True, 'use_batch_normalization': False, 'n_layers_CNN': 2, 'pool_every_n_layers': 1, 'n_layers_hidden': 2} because of the following error: NameError(\"name 'img_height' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Avey\\miniforge3\\envs\\apvc\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Avey\\AppData\\Local\\Temp\\ipykernel_20128\\1207857609.py\", line 2, in objective\n",
      "    model = create_model(trial)  # Run model construction optimization\n",
      "  File \"C:\\Users\\Avey\\AppData\\Local\\Temp\\ipykernel_20128\\2304656070.py\", line 11, in create_model\n",
      "    tf.keras.layers.Input(shape=(img_height, img_width, 3)),\n",
      "NameError: name 'img_height' is not defined\n",
      "[W 2025-03-28 16:20:01,495] Trial 1 failed with value None.\n"
     ]
    }
   ],
   "source": [
    "# Optimize for n_trials, using all available threads, timeout of 5 min\n",
    "study.optimize(objective, n_trials=2, n_jobs=-1, timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f513e-7aa4-4931-a007-460fdefe4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best score\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac16fe6-4545-491a-be92-4e716d9846bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = create_model(study.best_trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
